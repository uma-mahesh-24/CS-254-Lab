{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uma-mahesh-24/CS-254-Lab/blob/main/CNN_FEA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrG-wvoWa_Ix",
        "outputId": "f8dc442a-8eee-486b-f123-1ec0c2c2dd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ====== 0) Setup\n",
        "!pip -q install tqdm\n",
        "\n",
        "import os, json, random, math, glob\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# ====== 1) Mount Google Drive & paths\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "root_dir = \"/content/drive/MyDrive\"\n",
        "data_dir = os.path.join(root_dir, \"corrected_dataset\")   # adjust if needed\n",
        "inputs_dir = os.path.join(data_dir, \"inputs\")\n",
        "targets_dir = os.path.join(data_dir, \"targets\")\n",
        "\n",
        "out_dir = os.path.join(root_dir, \"cnn_unet_baseline\")\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# ====== 2) Repro\n",
        "seed = 42\n",
        "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
        "\n",
        "# ====== 3) Dataset\n",
        "class NpyPairDataset(Dataset):\n",
        "    def __init__(self, inputs_dir, targets_dir, files):\n",
        "        self.inputs_dir = inputs_dir\n",
        "        self.targets_dir = targets_dir\n",
        "        self.files = files\n",
        "\n",
        "    def __len__(self): return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "        x = np.load(os.path.join(self.inputs_dir, fname)).astype(np.float32)  # (H,W)\n",
        "        y = np.load(os.path.join(self.targets_dir, fname)).astype(np.float32) # (H,W)\n",
        "\n",
        "        x = x[None, ...]   # (1,H,W)\n",
        "        y = y[None, ...]   # (1,H,W)\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": torch.from_numpy(x),\n",
        "            \"labels\": torch.from_numpy(y),\n",
        "            \"file_name\": fname,\n",
        "        }\n",
        "\n",
        "# ====== 4) Split (fixed)\n",
        "all_files = sorted([f for f in os.listdir(inputs_dir) if f.endswith(\".npy\")])\n",
        "random.Random(seed).shuffle(all_files)\n",
        "split_idx = int(0.9 * len(all_files))\n",
        "train_files = all_files[:split_idx]\n",
        "val_files   = all_files[split_idx:]\n",
        "\n",
        "train_ds = NpyPairDataset(inputs_dir, targets_dir, train_files)\n",
        "val_ds   = NpyPairDataset(inputs_dir, targets_dir, val_files)\n",
        "\n",
        "# ====== 5) Dataloaders\n",
        "batch_size = 4\n",
        "num_workers = 2\n",
        "pin_memory = True\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n",
        "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory, drop_last=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ---------- Utility ----------\n",
        "def pad_to_multiple(x, multiple=4):\n",
        "    \"\"\"Pad image tensor on right/bottom to be divisible by `multiple`.\"\"\"\n",
        "    _, _, H, W = x.shape\n",
        "    pad_h = (multiple - (H % multiple)) % multiple\n",
        "    pad_w = (multiple - (W % multiple)) % multiple\n",
        "    return F.pad(x, (0, pad_w, 0, pad_h)), pad_h, pad_w\n",
        "\n",
        "\n",
        "# ---------- Building Blocks ----------\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(Conv → BN → LeakyReLU → Conv → BN → LeakyReLU → Dropout)\"\"\"\n",
        "    def __init__(self, c_in, c_out, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(c_in, c_out, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(c_out, c_out, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(c_out),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscale with MaxPool then DoubleConv\"\"\"\n",
        "    def __init__(self, c_in, c_out, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.pool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(c_in, c_out, dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscale then DoubleConv with skip connection cropping.\"\"\"\n",
        "    def __init__(self, c_in, c_out, bilinear=True, dropout=0.1):\n",
        "        super().__init__()\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "            self.conv = DoubleConv(c_in, c_out, dropout)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(c_in // 2, c_in // 2, 2, stride=2)\n",
        "            self.conv = DoubleConv(c_in, c_out, dropout)\n",
        "\n",
        "    def crop(self, enc_feat, target):\n",
        "        _, _, H, W = target.shape\n",
        "        return enc_feat[:, :, :H, :W]\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        x2 = self.crop(x2, x1)\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "# ---------- Full U-Net ----------\n",
        "class UNetImproved(nn.Module):\n",
        "    def __init__(self, c_in=1, c_out=1, base=64, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(c_in, base, dropout)\n",
        "        self.down1 = Down(base, base * 2, dropout)\n",
        "        self.down2 = Down(base * 2, base * 4, dropout)\n",
        "        self.down3 = Down(base * 4, base * 8, dropout)  # deeper bottleneck\n",
        "\n",
        "        self.up1 = Up(base * 8 + base * 4, base * 4, dropout=dropout)\n",
        "        self.up2 = Up(base * 4 + base * 2, base * 2, dropout=dropout)\n",
        "        self.up3 = Up(base * 2 + base, base, dropout=dropout)\n",
        "        self.outc = nn.Conv2d(base, c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        H, W = x.shape[-2:]\n",
        "        x, pad_h, pad_w = pad_to_multiple(x, 8)\n",
        "\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "\n",
        "        x = self.up1(x4, x3)\n",
        "        x = self.up2(x, x2)\n",
        "        x = self.up3(x, x1)\n",
        "\n",
        "        out = self.outc(x)\n",
        "        return out[:, :, :H, :W]  # crop back to original size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = UNetImproved(base=64, dropout=0.1).to(device)\n",
        "\n",
        "# ====== 7) Losses & metrics\n",
        "def masked_mse_mean(pred, target):\n",
        "    mask = (target >= 0)\n",
        "    if mask.sum() == 0:\n",
        "        return torch.tensor(0.0, device=pred.device)\n",
        "    return ((pred - target)**2)[mask].mean()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_epoch():\n",
        "    model.eval()\n",
        "    mae_sum, rmse_sum, r2_numer, r2_denom, count = 0.0, 0.0, 0.0, 0.0, 0\n",
        "    for batch in val_loader:\n",
        "        x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
        "        y = batch[\"labels\"].to(device, non_blocking=True)\n",
        "        pred = model(x)\n",
        "\n",
        "        # gather masked vectors for metrics\n",
        "        mask = (y >= 0)\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        e = (pred - y)[mask]\n",
        "        mae_sum  += e.abs().mean().item()\n",
        "        rmse_sum += torch.sqrt((e**2).mean()).item()\n",
        "\n",
        "        # R2 (pixel-wise)\n",
        "        y_masked = y[mask]\n",
        "        ybar = y_masked.mean()\n",
        "        r2_numer += ((e)**2).sum().item()\n",
        "        r2_denom += ((y_masked - ybar)**2).sum().item()\n",
        "        count += 1\n",
        "\n",
        "    mae  = mae_sum / max(count,1)\n",
        "    rmse = rmse_sum / max(count,1)\n",
        "    r2   = 1.0 - (r2_numer / (r2_denom + 1e-12)) if r2_denom > 0 else float(\"nan\")\n",
        "    return {\"mae\": mae, \"rmse\": rmse, \"r2\": r2}\n",
        "\n",
        "# ====== 8) Optimizer & training loop\n",
        "epochs = 50\n",
        "lr = 5e-4\n",
        "weight_decay = 1e-2\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "best_rmse = float(\"inf\")\n",
        "best_r2 = float(\"-inf\") # Initialize best_r2\n",
        "best_path = os.path.join(out_dir, \"unet_tiny_best.pt\")\n",
        "checkpoint_path = os.path.join(out_dir, \"checkpoint.pt\")\n",
        "\n",
        "# Load checkpoint if exists\n",
        "start_epoch = 1\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    # Load state_dict with strict=False to ignore mismatched keys\n",
        "    model_state_dict = model.state_dict()\n",
        "    pretrained_state_dict = checkpoint['state_dict']\n",
        "\n",
        "    # Filter out unnecessary keys\n",
        "    filtered_state_dict = {k: v for k, v in pretrained_state_dict.items() if k in model_state_dict and v.shape == model_state_dict[k].shape}\n",
        "\n",
        "    model_state_dict.update(filtered_state_dict)\n",
        "    model.load_state_dict(model_state_dict)\n",
        "\n",
        "    # Load optimizer and scaler state, handling potential key mismatches\n",
        "    try:\n",
        "        opt.load_state_dict(checkpoint['optimizer'])\n",
        "    except ValueError as e:\n",
        "        print(f\"Could not load optimizer state dict: {e}. Starting with a new optimizer state.\")\n",
        "\n",
        "    try:\n",
        "        scaler.load_state_dict(checkpoint['scaler'])\n",
        "    except ValueError as e:\n",
        "        print(f\"Could not load scaler state dict: {e}. Starting with a new scaler state.\")\n",
        "\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    best_rmse = checkpoint.get('best_rmse', float('inf')) # Use .get with a default value\n",
        "    best_r2 = checkpoint.get('best_r2', float('-inf')) # Use .get with a default value\n",
        "\n",
        "    print(f\"Resumed training from epoch {start_epoch}\")\n",
        "\n",
        "\n",
        "for epoch in range(start_epoch, epochs+1):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "    running = 0.0\n",
        "    for batch in pbar:\n",
        "        x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
        "        y = batch[\"labels\"].to(device, non_blocking=True)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
        "            pred = model(x)\n",
        "            loss = masked_mse_mean(pred, y)\n",
        "\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        running += loss.item()\n",
        "        pbar.set_postfix(loss=f\"{running/ (pbar.n or 1):.4f}\")\n",
        "\n",
        "    metrics = eval_epoch()\n",
        "    print(f\"Epoch {epoch}: val_mae={metrics['mae']:.4f} \"\n",
        "          f\"val_rmse={metrics['rmse']:.4f} val_r2={metrics['r2']:.4f}\")\n",
        "\n",
        "    # save best by RMSE and record R2\n",
        "    if metrics[\"rmse\"] < best_rmse:\n",
        "        best_rmse = metrics[\"rmse\"]\n",
        "        best_r2 = metrics[\"r2\"]  # Record the corresponding R2\n",
        "        torch.save({\"state_dict\": model.state_dict(),\n",
        "                    \"metrics\": metrics,\n",
        "                    \"epoch\": epoch,\n",
        "                    'best_rmse': best_rmse, # Save best_rmse and best_r2 in best_path checkpoint\n",
        "                    'best_r2': best_r2}, best_path)\n",
        "        print(f\"  ↳ saved best to {best_path}\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': opt.state_dict(),\n",
        "        'scaler': scaler.state_dict(),\n",
        "        'best_rmse': best_rmse,\n",
        "        'best_r2': best_r2\n",
        "    }, checkpoint_path)\n",
        "    print(f\"  ↳ saved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "print(\"Best val RMSE:\", best_rmse)\n",
        "print(\"Corresponding val R2:\", best_r2) # Print the best R2\n",
        "\n",
        "# # ====== 9) Inference helper (save predictions for the val set)\n",
        "# @torch.no_grad()\n",
        "# def save_val_predictions(save_dir):\n",
        "#     os.makedirs(save_dir, exist_ok=True)\n",
        "#     model.eval()\n",
        "#     for batch in tqdm(val_loader, desc=\"Saving val preds\"):\n",
        "#         x = batch[\"pixel_values\"].to(device, non_blocking=True)\n",
        "#         fnames = batch[\"file_name\"]\n",
        "#         pred = model(x).cpu().numpy()  # [B,1,H,W]\n",
        "#         for i, fname in enumerate(fnames):\n",
        "#             np.save(os.path.join(save_dir, fname), pred[i,0])\n",
        "\n",
        "# pred_dir = os.path.join(out_dir, \"preds_val\")\n",
        "# save_val_predictions(pred_dir)\n",
        "# print(\"Predictions saved to:\", pred_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHdN_RnrgHEe",
        "outputId": "d8377e6b-75ed-47bd-ae37-ec9b9666a5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2605971602.py:144: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint from /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n",
            "Could not load optimizer state dict: loaded state dict contains a parameter group that doesn't match the size of optimizer's group. Starting with a new optimizer state.\n",
            "Resumed training from epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 19/50:   0%|          | 0/788 [00:00<?, ?it/s]/tmp/ipython-input-2605971602.py:194: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: val_mae=0.1578 val_rmse=0.2622 val_r2=0.0799\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: val_mae=0.1573 val_rmse=0.2615 val_r2=0.0847\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: val_mae=0.1571 val_rmse=0.2591 val_r2=0.1032\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: val_mae=0.1741 val_rmse=0.2646 val_r2=0.0761\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: val_mae=0.1507 val_rmse=0.2607 val_r2=0.0880\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: val_mae=0.1692 val_rmse=0.2636 val_r2=0.0798\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: val_mae=0.1583 val_rmse=0.2577 val_r2=0.1153\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: val_mae=0.1569 val_rmse=0.2563 val_r2=0.1220\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: val_mae=0.1684 val_rmse=0.2594 val_r2=0.1102\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: val_mae=0.1500 val_rmse=0.2524 val_r2=0.1477\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: val_mae=0.1470 val_rmse=0.2480 val_r2=0.1766\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: val_mae=0.1476 val_rmse=0.2468 val_r2=0.1860\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: val_mae=0.1470 val_rmse=0.2456 val_r2=0.1933\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: val_mae=0.1548 val_rmse=0.2480 val_r2=0.1847\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: val_mae=0.1666 val_rmse=0.2548 val_r2=0.1492\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: val_mae=0.1473 val_rmse=0.2444 val_r2=0.2036\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: val_mae=0.1471 val_rmse=0.2430 val_r2=0.2125\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: val_mae=0.1431 val_rmse=0.2414 val_r2=0.2195\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: val_mae=0.1469 val_rmse=0.2480 val_r2=0.1777\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: val_mae=0.1540 val_rmse=0.2447 val_r2=0.2075\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: val_mae=0.1413 val_rmse=0.2397 val_r2=0.2309\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: val_mae=0.1416 val_rmse=0.2388 val_r2=0.2366\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: val_mae=0.1690 val_rmse=0.2551 val_r2=0.1506\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: val_mae=0.1419 val_rmse=0.2387 val_r2=0.2371\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: val_mae=0.1427 val_rmse=0.2393 val_r2=0.2332\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: val_mae=0.1415 val_rmse=0.2372 val_r2=0.2473\n",
            "  ↳ saved best to /content/drive/MyDrive/cnn_unet_baseline/unet_tiny_best.pt\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: val_mae=0.1433 val_rmse=0.2381 val_r2=0.2422\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: val_mae=0.1427 val_rmse=0.2395 val_r2=0.2313\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: val_mae=0.1455 val_rmse=0.2384 val_r2=0.2435\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: val_mae=0.1418 val_rmse=0.2374 val_r2=0.2467\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: val_mae=0.1525 val_rmse=0.2429 val_r2=0.2191\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: val_mae=0.1439 val_rmse=0.2381 val_r2=0.2434\n",
            "  ↳ saved checkpoint to /content/drive/MyDrive/cnn_unet_baseline/checkpoint.pt\n",
            "Best val RMSE: 0.2372476402670145\n",
            "Corresponding val R2: 0.2473417485400904\n"
          ]
        }
      ]
    }
  ]
}